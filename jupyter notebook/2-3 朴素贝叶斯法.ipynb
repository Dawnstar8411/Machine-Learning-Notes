{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事件$A_i$发生的概率记为$P(A_i)$，这个概率不考虑其他事件，是通过统计得到的，因此成为先验概率\n",
    "\n",
    "事件$A_i$在事件B发生的条件下发生的概率记作$P(A_i|B)$，其是在已知B发生后得到的概率，因此成为后验概率。\n",
    "\n",
    "$$P(A_i|B)=\\frac{P(B|A_i)P(A_i)}{\\sum_jP(B|A_j)P(A_j)}$$\n",
    "\n",
    "其中，$A_1,\\dots,A_n$为完备事件组，其合起来为整个全集，彼此之间没有交集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 朴素贝叶斯法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X是输入特征的集合，Y是输出类标的集合，$P(X,Y)$是X和Y的联合概率分布，训练数据集也由$P(X,Y)$独立同分布产生"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y是某一个类的概率$P(Y=c_k)$是先验分布，通过统计训练集可以得到。\n",
    "\n",
    "条件概率分布 $P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},\\dots,X^{(n)}=x^{(n)}|Y=c_k)$\n",
    "\n",
    "我们假设输入特征向量的每一个维度的可能取值是离散的，且数量有限，为$S_j$，那么总共的组合个数为$K\\prod_{j=1}^nS_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之所以称为**朴素贝叶斯法**，是因为其简化了情况，其假设输入向量的各个维度特征是条件独立的，则条件概率分布可写成\n",
    "\n",
    "$$P(X=x|Y=c_k)=\\prod_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)$$\n",
    "\n",
    "这样的话其组合的数量就变成了$K\\sum_jS_j$,通过统计训练集，这些条件概率都是可以计算出来的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们最终的目的是计算后验概率P(Y=c_k|X=x),即对于输入的向量x,其为类别$c_k$的概率。\n",
    "\n",
    "$$(Y=c_k|X=x)=\\frac{P(X=x|Y=c_k)P(Y=c_k)}{\\sum_jP(X=x|Y=c_j)P(Y=c_j)}$$\n",
    "\n",
    "当计算出后验概率后，使后验概率最大的类别即为输入特征所属的类别。朴素贝叶斯法进行分类的后验概率最大化准则等价于期望风险最小化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1朴素贝叶斯算法："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "输入：训练数据集，实例x\n",
    "\n",
    "输出：实例x的分类\n",
    "\n",
    "(1) 计算先验概率P(Y=c_k)和条件概率$P(X^{(j)}=a_{jl}|Y=c_k)$，这些都可以通过统计训练集来得到\n",
    "\n",
    "(2) 对于给定的实例x,计算$P(Y=c_k)\\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)$\n",
    "\n",
    "(3) 确定实例x的分类，因为分母都一样，所以只需要找出使分子最大的$c_k$来即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 贝叶斯估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用极大似然估计是可能会出现所要估计的概率值为0的情况。举个例子，输入样例在某个维度上应该有某个特征，但是训练集中不包含这种特征，所以按照最大似然估计的统计方式，其条件概率为0，但是在测试集中出现了包含此特征值的样例，便会影响到后验概率的计算结果，使分类产生偏差。因此可以使用贝叶斯估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_{\\lambda}(X^{(j)}=a_{jl}|Y=c_k)=\\frac{\\sum^N_{i=1}I(x_i^{(j)}=a_{jl},y_i=c_k)+\\lambda}{\\sum^N_{i=1}I(y_i=c_k)+S_j\\lambda}$$\n",
    "\n",
    "当$\\lambda=0$时，就是极大似然估计，常取$\\lambda=1$，这时称为拉普拉斯平滑，也有$\\sum^{S_j}_{i=1}P(X^{(j)}=a_{jl}|Y=c_k)=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先验概率的贝叶斯估计为：\n",
    "\n",
    "$$P_{\\lambda}(Y=c_k)=\\frac{\\sum^N_{i=1}I(y_i=c_k)+\\lambda}{N+K\\lambda}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
