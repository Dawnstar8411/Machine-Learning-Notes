{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习性能评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 模型选择策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 损失函数和风险函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习中，模型的输出值与真实值之间存在的差异，使用损失函数来度量这种差异。常用的损失函数有：\n",
    "- 0-1 损失函数\n",
    "- 平方损失函数(quadratic loss function)\n",
    "- 绝对损失函数(absolute loss function)\n",
    "- 对数损失函数(logarithmic loss function)或对数似然损失函数(log-likelihood loss function)\n",
    "\n",
    "损失函数值越小，模型就越好。由于模型的输入，输出(X,Y)是随机变量，遵循联合分布P(X,Y),损失函数的期望便是理论上模型关于联合分布的平均意义下的损失，称为期望风险。由于不知道联合概率分布，因此无法直接计算期望风险。在监督学习中，我们采用有限数量的数据进行训练，可得到模型在该数据集上的平均损失，称之为经验风险。根据大数定律，当样本容量N趋于无穷时，经验风险趋于期望风险，便可以用经验风险来代替期望风险。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 经验风险最小化与结构风险最小化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经验风险最小化策略解决最优化问题：\n",
    "$$\\min_{f\\in F}\\frac{1}{N}\\sum^N_{i=1}L(y_i,f(x_i))$$\n",
    "当样本容量足够大时，经验风险最小化能保证有很好的的学习效果。当模型是条件概率分布、损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结构风险最小化是为了防止样本容量很小时出现过拟合而提出的策略。结构风险在经验风险上加上表示模型复杂度的正则化项(regularizer)或惩罚项(penalty term),其定义为：\n",
    "$$R_{srm}(f)=\\frac{1}{N}\\sum^N_{i=1}L(y_i,f(x_i))+\\lambda J(f)$$\n",
    "$J(f)$表示了对模型复杂度的惩罚，$\\lambda$是平衡系数。结构风险小需要经验风险和模型复杂度同时小。因为在小规模数据集上训练的复杂模型很容易过拟合。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于贝叶斯估计中的最大后验概率估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 相关概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过拟合是指学习时选择的模型所包含的参数过多，以至于出现这一模型对已知数据预测的很好，对未知数据预测的很差的现象。\n",
    "\n",
    "奥卡姆剃刀原理：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型。从贝叶斯估计的角度来看，正则化项对应于模型的先验概率，可以假设复杂的模型有较小的先验概率，简单地模型有较大的的先验概率。\n",
    "\n",
    "交叉验证：\n",
    "- 简单交叉验证：将数据随机分为两部分，一部分用作训练，一部分用作测试\n",
    "- S折交叉验证：随机地将数据切分为S个互不相交、大小相同的子集；然后利用S-1个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的S中选择重复进行，最后选出S次测评中平均测试误差最小的模型。\n",
    "- 留一交叉验证：S折交叉验证的特殊情况，S=N，N为数据个数\n",
    "\n",
    "学习方法的泛化能力是指由该方法学习到的模型对未知数据的预测能力。\n",
    "\n",
    "泛化误差上界是样本容量的函数，当样本容量增加时，泛化上界趋于0；其也是假设空间容量的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 分类模型性能评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 分类准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。但是，当样本数量不均衡时，例如1000个样例中有995个正例，5个负例，分类器只要将所有的样本都判定为正，也可以得到99.5%的准确率。所有分类准确率并不能很好的对分类模型进行评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 精确率与召回率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二分类问题，分类器在测试集上的结果一共有四种：\n",
    "- TP:将正类预测为正类数\n",
    "- FN:将正类预测为负类数\n",
    "- FP:将负类预测为正类数\n",
    "- TN:将负类预测为负类数\n",
    "精确率可以定义为：\n",
    "$$precision=\\frac{TP}{TP+FP}$$\n",
    "召回率可以定义为:\n",
    "$$recall=\\frac{TP}{TP+FN}$$\n",
    "F1值是精确率与召回率的调和均值：\n",
    "$$F_1=\\frac{2TP}{2TP+FP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 P-R曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每一个precision和recall值都是在特定的分类阈值下计算出来的，通过设置不同的阈值，可以得到多组precision和recall值，以recall为横坐标，precision为纵坐标，即可以画出P-R曲线。假设有N个测试样本，分类器会给出每个测试样本属于正类的概率值(0-1之间)，将N个样本按照概率值从高到低排列。给定从大到小不同的阈值，对样本进行正负类分类，同时计算precision和recall值。计算多组后，即可画出PR曲线，PR曲线下方面积称为Average Precision(AP),如果有多个类别，可以计算Mean Average Precision值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 ROC曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC曲线的横坐标为false positive rate: $FPR=\\frac{FP}{FP+TN}$,是指所有负例中被检测为正例的概率。\n",
    "\n",
    "纵坐标为true positive rate:$TPR=\\frac{TP}{TP+FN}$,是指所有正例中被检测为正例的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照P-R曲线的画法，也可以画出ROC曲线，该曲线越靠近左上角，说明分类器的效果越好。当测试集中正负样本的分布变化时，ROC曲线能够保持不变，而P-R曲线会变化剧烈，故ROC曲线经常被使用。AUC(Area Under Curve)被定义为ROC曲线下的面积，完全随机的二分类器的AUC为0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
